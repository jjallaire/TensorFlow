% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/serve.R
\name{serve_savedmodel}
\alias{serve_savedmodel}
\title{Serve a TensorFlow Model}
\usage{
serve_savedmodel(model_dir, host = "127.0.0.1", port = 8089,
  daemonized = FALSE)
}
\arguments{
\item{model_dir}{The path to the exported model, as a string.}

\item{host}{Address to use to serve model, as a string.}

\item{port}{Port to use to serve model, as numeric.}

\item{daemonized}{Makes 'httpuv' server daemonized so R interactive sessions
are not blocked to handle requests. To terminate a daemonized server, call
'httpuv::stopDaemonizedServer()' with the handle returned from this call.}
}
\description{
Serve a TensorFlow Model into a local REST/JSON API.
}
\examples{
\dontrun{

library(tensorflow)
sess <- tf$Session()

# (1) Train MNIST model.

# (2) Save model with signature.

model_dir <- "trained"
builder <- tf$saved_model$builder$SavedModelBuilder(model_dir)
builder$add_meta_graph_and_variables(
  sess,
  list(
    tf$python$saved_model$tag_constants$SERVING
  ),
  signature_def_map = list(
    serving_default = tf$saved_model$signature_def_utils$build_signature_def(
      inputs = list(images = tf$saved_model$utils$build_tensor_info(x)),
      outputs = list(scores = tf$saved_model$utils$build_tensor_info(y))
    )
  )
)
builder$save()

# (3) Serve saved model.

serve_savedmodel(model_dir)
}
}
